# 第十四屆國會國際學術研討會「民主危機下的國會角色」



<div style="text-align: justify">

### Presentation: When Speaking of *Pork*: Exploring Parliamentary Questions Using NLP Transformers

In this article, I quantitatively investigate legislators' electoral strategies and communication style by applying an encoder-decoder-based models to measure pork-barrel features on the parliamentary questions proposed by the legislators from 1993 to 2020. To incorporate this application into our analysis, I have trained a deep learning classifier with BERT (Bidirectional Encoder Representative from Transformers) on the human-labelled pork-barrel legislation, including the bills and the amendments from Taiwan’s legislature (the Legislative Yuan). The collection of legislation are annotated with binary-instance classification by reading the text, devoted either to promoting the pork-barrel project (earmarked projects) or cultivating favoured minorities by providing subsidies. With attention mechanisms in transformers architecture, BERT model not only learns the condensed features of bag-of-words but also has better tokenization algorithms for handling unseen words. With the pork-barrel  features identified by the trained model, I find that legislators under SNTV (single non-transferable voting ) are likely to express political intension with regards to pork barrel projects in written parliamentary questions and seek personal votes by promising particularistic benefits to their targeted supporters. Consistent with the literature, switching from SNTV to Single-Member Districts decrease legislators' incentives to bring home the bacon but increases their attention to universalism (national) policies.

**Keywords**：*electoral reform, single-member districts (SMDs), distributive politics, deep learning, Transformers, BERT*


**Session**: 

**Time**: 

**File**: 

</div>

